{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os.path as osp\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, root, transform = None, preload = False):\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        self.fileNames = []\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        \n",
    "        for i in range(10):\n",
    "            for filename in glob.glob(osp.join(root, str(i), \"*.png\")):\n",
    "                self.fileNames.append((filename, i))\n",
    "\n",
    "        self.len = len(self.fileNames)\n",
    "        \n",
    "        if preload: self.__preload()\n",
    "        \n",
    "    def __preload(self):\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        for fn, label in self.fileNames:\n",
    "            self.images.append(cv2.cvtColor(cv2.imread(fn), cv2.COLOR_BGR2GRAY))\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = None\n",
    "        image = None\n",
    "        if self.images is not None:\n",
    "            image = self.images[index]\n",
    "            label = self.labels[index]\n",
    "        else:\n",
    "            fn, label = self.fileNames[index]\n",
    "            image = cv2.imread(fn)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MNISTDataset(\"./mnist_png/training\", \n",
    "                        transform = transforms.ToTensor(), \n",
    "                        preload = True)\n",
    "\n",
    "testset = MNISTDataset(\"./mnist_png/testing\", \n",
    "                        transform = transforms.ToTensor(), \n",
    "                        preload = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set length = 60000\n",
      "test set length = 10000\n"
     ]
    }
   ],
   "source": [
    "trainsetLoader = DataLoader(trainset, batch_size = 64, shuffle = True, num_workers = 1)\n",
    "testsetLoader = DataLoader(testset, batch_size = 1000, shuffle = False, num_workers = 1)\n",
    "print(f\"train set length = {len(trainset)}\")\n",
    "print(f\"test set length = {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def imshow(img):\n",
    "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(trainsetLoader)\n",
    "image, label = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "useCuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if useCuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.maxPool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.dropOut2 = nn.Dropout2d()\n",
    "        self.maxPool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.maxPool1(self.conv1(x)))\n",
    "        x = self.relu2(self.maxPool2(self.dropOut2(self.conv2(x))))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.log_softmax(self.fc2(x), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def train(model, trainDataLoader, testDataLoader, epoch, logInterval = 100):\n",
    "    model.train()\n",
    "    iteration = 0\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    for e in range(epoch):\n",
    "        start = time()\n",
    "        for batchIndex, (data, label) in enumerate(trainDataLoader):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if iteration % logInterval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    e, batchIndex * len(data), len(trainDataLoader.dataset),\n",
    "                    100. * batchIndex / len(trainDataLoader), loss.item()))\n",
    "            iteration += 1\n",
    "        end = time()\n",
    "        print('{:.2f}s'.format(end-start))\n",
    "\n",
    "def test(model, testDataLoader):\n",
    "    model.eval()\n",
    "    testLoss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testDataLoader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            testLoss = F.nll_loss(output, target, size_average=False).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    testLoss /= len(testDataLoader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        testLoss, correct, len(testDataLoader.dataset),\n",
    "        100. * correct / len(testDataLoader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.295003\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.301767\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.284818\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.254495\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.149849\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 1.841183\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 1.171233\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.969552\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.619123\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.604459\n",
      "32.07s\n",
      "Train Epoch: 1 [3968/60000 (7%)]\tLoss: 0.400573\n",
      "Train Epoch: 1 [10368/60000 (17%)]\tLoss: 0.709443\n",
      "Train Epoch: 1 [16768/60000 (28%)]\tLoss: 0.514449\n",
      "Train Epoch: 1 [23168/60000 (39%)]\tLoss: 0.548188\n",
      "Train Epoch: 1 [29568/60000 (49%)]\tLoss: 0.472444\n",
      "Train Epoch: 1 [35968/60000 (60%)]\tLoss: 0.408589\n",
      "Train Epoch: 1 [42368/60000 (71%)]\tLoss: 0.379076\n",
      "Train Epoch: 1 [48768/60000 (81%)]\tLoss: 0.614471\n",
      "Train Epoch: 1 [55168/60000 (92%)]\tLoss: 0.558267\n",
      "31.24s\n",
      "Train Epoch: 2 [1536/60000 (3%)]\tLoss: 0.301060\n",
      "Train Epoch: 2 [7936/60000 (13%)]\tLoss: 0.278541\n",
      "Train Epoch: 2 [14336/60000 (24%)]\tLoss: 0.274342\n",
      "Train Epoch: 2 [20736/60000 (35%)]\tLoss: 0.467988\n",
      "Train Epoch: 2 [27136/60000 (45%)]\tLoss: 0.461315\n",
      "Train Epoch: 2 [33536/60000 (56%)]\tLoss: 0.364175\n",
      "Train Epoch: 2 [39936/60000 (67%)]\tLoss: 0.226001\n",
      "Train Epoch: 2 [46336/60000 (77%)]\tLoss: 0.260411\n",
      "Train Epoch: 2 [52736/60000 (88%)]\tLoss: 0.224533\n",
      "Train Epoch: 2 [59136/60000 (99%)]\tLoss: 0.309803\n",
      "31.81s\n",
      "Train Epoch: 3 [5504/60000 (9%)]\tLoss: 0.359809\n",
      "Train Epoch: 3 [11904/60000 (20%)]\tLoss: 0.396291\n",
      "Train Epoch: 3 [18304/60000 (30%)]\tLoss: 0.335756\n",
      "Train Epoch: 3 [24704/60000 (41%)]\tLoss: 0.152993\n",
      "Train Epoch: 3 [31104/60000 (52%)]\tLoss: 0.149035\n",
      "Train Epoch: 3 [37504/60000 (62%)]\tLoss: 0.224263\n",
      "Train Epoch: 3 [43904/60000 (73%)]\tLoss: 0.242860\n",
      "Train Epoch: 3 [50304/60000 (84%)]\tLoss: 0.211891\n",
      "Train Epoch: 3 [56704/60000 (94%)]\tLoss: 0.226339\n",
      "32.50s\n",
      "Train Epoch: 4 [3072/60000 (5%)]\tLoss: 0.291406\n",
      "Train Epoch: 4 [9472/60000 (16%)]\tLoss: 0.181781\n",
      "Train Epoch: 4 [15872/60000 (26%)]\tLoss: 0.125767\n",
      "Train Epoch: 4 [22272/60000 (37%)]\tLoss: 0.171954\n",
      "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.283057\n",
      "Train Epoch: 4 [35072/60000 (58%)]\tLoss: 0.411958\n",
      "Train Epoch: 4 [41472/60000 (69%)]\tLoss: 0.158572\n",
      "Train Epoch: 4 [47872/60000 (80%)]\tLoss: 0.228278\n",
      "Train Epoch: 4 [54272/60000 (90%)]\tLoss: 0.195609\n",
      "31.66s\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "train(model, trainsetLoader, testsetLoader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 9595/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, testsetLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
